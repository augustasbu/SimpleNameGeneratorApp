{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Getting and \"cleaning\" the dataset"
      ],
      "metadata": {
        "id": "SEmivNwk-sY4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hA8qS142ldri"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "m_names = []\n",
        "f_names = []\n",
        "for key in ['a', 'b', 'c', 'c-2', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "            'm', 'n', 'o', 'p', 'r', 's', 's-2', 't', 'u', 'v', 'z', 'z-2']:\n",
        "    url = f'https://vardai.vlkk.lt/sarasas/{key}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    m_links = soup.find_all('a', class_='names_list__links names_list__links--man')\n",
        "    f_links = soup.find_all('a', class_='names_list__links names_list__links--woman')\n",
        "    m_names += [m_name.text for m_name in m_links]\n",
        "    f_names += [f_name.text for f_name in f_links]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine both lists\n",
        "combined_lists = m_names + f_names\n",
        "\n",
        "# Get all unique characters\n",
        "unique_chars = set(\"\".join(combined_lists))\n",
        "\n",
        "# Sort the characters for better readability (optional)\n",
        "unique_chars = sorted(unique_chars)\n",
        "\n",
        "# Print the result\n",
        "print(\"Unique characters:\", unique_chars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtGMzYv4yMeG",
        "outputId": "393615e9-948b-4632-ad37-a5bc36b826c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique characters: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ą', 'č', 'ė', 'ę', 'š', 'ū', 'ž']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_names(names):\n",
        "  # Define the character mappings, including capital letters to lowercase\n",
        "  char_mappings = {\n",
        "      'Á': 'a',\n",
        "      'Ã': 'a',\n",
        "      'È': 'e',\n",
        "      'Ì': 'i',\n",
        "      'Ò': 'o',\n",
        "      'Õ': 'o',\n",
        "      'Ù': 'u',\n",
        "      'à': 'a',\n",
        "      'á': 'a',\n",
        "      'ã': 'a',\n",
        "      'è': 'e',\n",
        "      'é': 'e',\n",
        "      'ì': 'i',\n",
        "      'ñ': 'n',\n",
        "      'ò': 'o',\n",
        "      'ó': 'o',\n",
        "      'õ': 'o',\n",
        "      'ù': 'u',\n",
        "      'ý': 'y',\n",
        "      'Ą': 'ą',\n",
        "      'Č': 'č',\n",
        "      'Ė': 'ė',\n",
        "      'ĩ': 'i',\n",
        "      'Š': 'š',\n",
        "      'ũ': 'u',\n",
        "      'Ū': 'ū',\n",
        "      'Ž': 'ž',\n",
        "      'Ẽ': 'e',\n",
        "      'ẽ': 'e',\n",
        "      'ỹ': 'y',\n",
        "      '̀': '',\n",
        "      '́': '',\n",
        "      '̃': '',\n",
        "      }\n",
        "\n",
        "  # Add uppercase-to-lowercase mappings\n",
        "  char_mappings.update({chr(i): chr(i).lower() for i in range(ord('A'), ord('Z') + 1)})\n",
        "\n",
        "  # Replace unwanted characters\n",
        "  def replace_chars(name, mappings):\n",
        "     for old_char, new_char in mappings.items():\n",
        "         name = name.replace(old_char, new_char)\n",
        "     return name\n",
        "\n",
        "  # Apply the replacement to each name\n",
        "  names_cleaned = [replace_chars(name.strip(), char_mappings) for name in names]\n",
        "  return names_cleaned"
      ],
      "metadata": {
        "collapsed": true,
        "id": "byCdc0Oyloe5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_names = clean_names(m_names)\n",
        "#m_names = [f\"M{name}\" for name in m_names]\n",
        "f_names = clean_names(f_names)\n",
        "#f_names = [f\"F{name}\" for name in f_names]\n",
        "#names = m_names + f_names"
      ],
      "metadata": {
        "id": "d98LjMtMy-8f"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model acts a bit weird when female start letter is ė. And we can clearly see why."
      ],
      "metadata": {
        "id": "ApN10xeB_WV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = len(list(filter(lambda item: item.startswith(\"ė\"), f_names)))\n",
        "print(f\"Number of strings starting with 'ė': {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTlkp4Dy_Vdu",
        "outputId": "2c32efd4-0392-4b8b-ddf2-b2598130c1cc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of strings starting with 'ė': 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save list to a .txt file\n",
        "with open(\"vardai_female\", \"w\") as file:\n",
        "    for item in f_names:\n",
        "        file.write(f\"{item}\\n\")\n",
        "\n",
        "with open(\"vardai_male\", \"w\") as file:\n",
        "    for item in m_names:\n",
        "        file.write(f\"{item}\\n\")\n",
        "\n",
        "#with open(\"vardai\", \"w\") as file:\n",
        "#    for item in names:\n",
        "#        file.write(f\"{item}\\n\")\n",
        "\n",
        "# Download the file to your local system\n",
        "from google.colab import files\n",
        "files.download(\"vardai_male\")\n",
        "files.download(\"vardai_female\")\n",
        "#files.download(\"vardai\")\n",
        "\n",
        "# add names as the first entry"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RoSlkFixq5in",
        "outputId": "a0a33ca1-347d-40d7-eedb-c0e372ec1347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_05eac21a-64e9-4fe9-9081-ee3f39a4b792\", \"vardai_male\", 33020)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fb1e7909-71bf-4c37-bc0c-e26d624ee3d6\", \"vardai_female\", 34191)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is pretty much the same as the one used in the lecutre"
      ],
      "metadata": {
        "id": "vDpYKXUD-0kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "P5_-7VxzZ8lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusted NameDataset\n",
        "class NameDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        self.names = pd.read_csv(csv_file)['name'].values\n",
        "        self.chars = sorted(list(set(''.join(self.names) + ' ')))  # Including a padding character\n",
        "        self.char_to_int = {c: i for i, c in enumerate(self.chars)}\n",
        "        self.int_to_char = {i: c for c, i in self.char_to_int.items()}\n",
        "        self.vocab_size = len(self.chars)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.names[idx] + ' '  # Adding padding character at the end\n",
        "        encoded_name = [self.char_to_int[char] for char in name]\n",
        "        return torch.tensor(encoded_name)\n",
        "\n",
        "# Custom collate function for padding\n",
        "def pad_collate(batch):\n",
        "    padded_seqs = pad_sequence(batch, batch_first=True, padding_value=0)\n",
        "    input_seq = padded_seqs[:, :-1]\n",
        "    target_seq = padded_seqs[:, 1:]\n",
        "    return input_seq, target_seq\n",
        "\n",
        "csv_file_male = 'vardai_male'\n",
        "csv_file_female = 'vardai_female'\n",
        "#csv_file = 'vardai'\n",
        "\n",
        "#dataset = NameDataset(csv_file)\n",
        "dataset_male = NameDataset(csv_file_male)\n",
        "dataset_female = NameDataset(csv_file_female)\n",
        "\n",
        "dataloader_male = DataLoader(dataset_male, batch_size=32, shuffle=True, collate_fn=pad_collate)\n",
        "dataloader_female = DataLoader(dataset_female, batch_size=32, shuffle=True, collate_fn=pad_collate)"
      ],
      "metadata": {
        "id": "69ltnwF1HEhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\""
      ],
      "metadata": {
        "id": "uotXcS2mRXd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimal Transformer Model\n",
        "class MinimalTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, num_heads, forward_expansion):\n",
        "        super(MinimalTransformer, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1, 100, embed_size))\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=num_heads)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=4)\n",
        "        self.output_layer = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        positions = torch.arange(0, x.size(1)).unsqueeze(0)\n",
        "        x = self.embed(x) + self.positional_encoding[:, :x.size(1), :]\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "# Training Loop\n",
        "def train_model(model, dataloader, epochs=30):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Ensure the model is in training mode\n",
        "        total_loss = 0.0\n",
        "        batch_count = 0\n",
        "\n",
        "        for batch_idx, (input_seq, target_seq) in enumerate(dataloader):\n",
        "            input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(input_seq)\n",
        "            loss = criterion(output.transpose(1, 2), target_seq)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            batch_count += 1\n",
        "\n",
        "        average_loss = total_loss / batch_count\n",
        "        print(f'Epoch {epoch+1}, Average Loss: {average_loss}')"
      ],
      "metadata": {
        "id": "fmZjdwrmHITY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelM = MinimalTransformer(vocab_size=dataset_male.vocab_size, embed_size=128, num_heads=8, forward_expansion=4).to(device)\n",
        "train_model(modelM, dataloader_male)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k0D4WR_HIPD",
        "outputId": "e241dff1-79f4-4000-cd40-b259c17a5150",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 1.362299338845182\n",
            "Epoch 2, Average Loss: 1.194868588743131\n",
            "Epoch 3, Average Loss: 1.1847481067515602\n",
            "Epoch 4, Average Loss: 1.1654071591117166\n",
            "Epoch 5, Average Loss: 1.152295225415348\n",
            "Epoch 6, Average Loss: 1.1525752145396777\n",
            "Epoch 7, Average Loss: 1.1441421966907406\n",
            "Epoch 8, Average Loss: 1.1326697444127611\n",
            "Epoch 9, Average Loss: 1.138304806937856\n",
            "Epoch 10, Average Loss: 1.1292295436228603\n",
            "Epoch 11, Average Loss: 1.130467475938403\n",
            "Epoch 12, Average Loss: 1.1189188193683781\n",
            "Epoch 13, Average Loss: 1.1207558887063964\n",
            "Epoch 14, Average Loss: 1.12533748396172\n",
            "Epoch 15, Average Loss: 1.1261435811184655\n",
            "Epoch 16, Average Loss: 1.1184927254668937\n",
            "Epoch 17, Average Loss: 1.1197640053496873\n",
            "Epoch 18, Average Loss: 1.114803169877076\n",
            "Epoch 19, Average Loss: 1.1093780048622572\n",
            "Epoch 20, Average Loss: 1.1183522442155633\n",
            "Epoch 21, Average Loss: 1.11354104546476\n",
            "Epoch 22, Average Loss: 1.105784262507415\n",
            "Epoch 23, Average Loss: 1.1102416559684376\n",
            "Epoch 24, Average Loss: 1.1078325721843183\n",
            "Epoch 25, Average Loss: 1.1062582105644478\n",
            "Epoch 26, Average Loss: 1.1030599662095062\n",
            "Epoch 27, Average Loss: 1.1050229530689144\n",
            "Epoch 28, Average Loss: 1.1061047891939968\n",
            "Epoch 29, Average Loss: 1.10405111017306\n",
            "Epoch 30, Average Loss: 1.1003837516485167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelF = MinimalTransformer(vocab_size=dataset_female.vocab_size, embed_size=128, num_heads=8, forward_expansion=4).to(device)\n",
        "train_model(modelF, dataloader_female)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-sNcOFNypx2",
        "outputId": "5f41e3be-1fc7-4fc1-a148-4e5c1f308950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 1.4203582016148961\n",
            "Epoch 2, Average Loss: 1.2449012555574115\n",
            "Epoch 3, Average Loss: 1.2238642232758659\n",
            "Epoch 4, Average Loss: 1.2059936460695768\n",
            "Epoch 5, Average Loss: 1.1959791071432875\n",
            "Epoch 6, Average Loss: 1.193355529380024\n",
            "Epoch 7, Average Loss: 1.1857151447382188\n",
            "Epoch 8, Average Loss: 1.1847558886484992\n",
            "Epoch 9, Average Loss: 1.1774727724548568\n",
            "Epoch 10, Average Loss: 1.1711439508244508\n",
            "Epoch 11, Average Loss: 1.1724663497810077\n",
            "Epoch 12, Average Loss: 1.16547133331012\n",
            "Epoch 13, Average Loss: 1.1635712273138807\n",
            "Epoch 14, Average Loss: 1.1634415101287956\n",
            "Epoch 15, Average Loss: 1.1562715208620058\n",
            "Epoch 16, Average Loss: 1.1620068406700192\n",
            "Epoch 17, Average Loss: 1.1642670770336812\n",
            "Epoch 18, Average Loss: 1.1616523113465846\n",
            "Epoch 19, Average Loss: 1.1546482977114225\n",
            "Epoch 20, Average Loss: 1.1660183242389135\n",
            "Epoch 21, Average Loss: 1.1604627326018828\n",
            "Epoch 22, Average Loss: 1.1505942344665527\n",
            "Epoch 23, Average Loss: 1.1552493428825437\n",
            "Epoch 24, Average Loss: 1.1601467284941136\n",
            "Epoch 25, Average Loss: 1.155124657136157\n",
            "Epoch 26, Average Loss: 1.1553474601946379\n",
            "Epoch 27, Average Loss: 1.1555279582962954\n",
            "Epoch 28, Average Loss: 1.1559429984343679\n",
            "Epoch 29, Average Loss: 1.152691332469309\n",
            "Epoch 30, Average Loss: 1.156044482288504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: the actual app uses the sample function with temperature.\n",
        "I could not get the model to distinguish between genders."
      ],
      "metadata": {
        "id": "MQJNwds2-78s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(model, dataset, start_str='a', max_length=20):\n",
        "    model.eval()  # Switch to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        # Convert start string to tensor\n",
        "        chars = [dataset.char_to_int[c] for c in start_str]\n",
        "        input_seq = torch.tensor(chars).unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "        output_name = start_str\n",
        "        for _ in range(max_length - len(start_str)):\n",
        "            output = model(input_seq.to(device)).to('cpu')\n",
        "\n",
        "            # Get the last character from the output\n",
        "            probabilities = torch.softmax(output[0, -1], dim=0)\n",
        "            # Sample a character from the probability distribution\n",
        "            next_char_idx = torch.multinomial(probabilities, 1).item()\n",
        "            next_char = dataset.int_to_char[next_char_idx]\n",
        "\n",
        "            if next_char == ' ':  # Assume ' ' is your end-of-sequence character\n",
        "                break\n",
        "\n",
        "            output_name += next_char\n",
        "            # Update the input sequence for the next iteration\n",
        "            input_seq = torch.cat([input_seq.to('cpu'), torch.tensor([[next_char_idx]])], dim=1)\n",
        "\n",
        "        return output_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqoHskUAQLF8",
        "outputId": "52344f69-df16-41a5-b4e6-0124867aa086",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Farma\n",
            "Farvaniju\n",
            "Farmila\n",
            "Farvida\n",
            "Fargva\n",
            "Farvuzija\n",
            "Farinanama\n",
            "Farga\n",
            "Faragenas\n",
            "Farcna\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training your model, generate a name starting with a specific letter\n",
        "for _ in range(10):\n",
        "    generated_name = sample(modelM, dataset_male, start_str='ar')\n",
        "    print(generated_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsfnIQ0hyVQM",
        "outputId": "603934e3-cb90-43e6-de22-b18a70036ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ardviudas\n",
            "arsmantijudas\n",
            "arvis\n",
            "argineolmas\n",
            "arivaldas\n",
            "arofas\n",
            "arilintas\n",
            "arolijus\n",
            "arriolmas\n",
            "arnijus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training your model, generate a name starting with a specific letter\n",
        "for _ in range(10):\n",
        "    generated_name = sample(modelF, dataset_female, start_str='a')\n",
        "    print(generated_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LZJFYH-ygsE",
        "outputId": "e610df09-306c-4c02-808d-4520e3c63984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aoranta\n",
            "adasa\n",
            "aive\n",
            "anainė\n",
            "avė\n",
            "aeudonia\n",
            "arestė\n",
            "afrmboda\n",
            "alelėja\n",
            "aremaretė\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "torch.save(modelM, '../namesformer_model_male.pt')\n",
        "torch.save(modelF, '../namesformer_model_female.pt')\n",
        "\n",
        "\n",
        "with open('../int_to_char_female.json', 'w') as f:\n",
        "    json.dump(dataset_female.int_to_char, f)\n",
        "\n",
        "with open('../char_to_int_female.json', 'w') as f:\n",
        "    json.dump(dataset_female.char_to_int, f)\n",
        "\n",
        "with open('../int_to_char_male.json', 'w') as f:\n",
        "    json.dump(dataset_male.int_to_char, f)\n",
        "\n",
        "with open('../char_to_int_male.json', 'w') as f:\n",
        "    json.dump(dataset_male.char_to_int, f)"
      ],
      "metadata": {
        "id": "WHNNVqols3NV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}